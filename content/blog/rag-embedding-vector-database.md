---
title: 一文搞懂 RAG：Embedding、Vector Database 与大模型如何协作
date: 2026-01-22
summary: 从工程视角系统解释 RAG 的核心概念：什么是 Embedding、什么是 Vector Database，以及它们如何与大模型协作构建检索增强生成系统。
---

当大模型不再"死记硬背"，而是学会"先查资料再回答"，
Retrieval-Augmented Generation（RAG）应运而生。

本文将从工程视角出发，系统解释：

- 什么是 Embedding
- 什么是 Vector Database
- 它们如何组成 RAG
- RAG 在实际系统中是如何工作的

## 一、为什么需要 RAG？

大模型（如 GPT）有两个天然限制：

1. **知识是静态的**
   - 训练完成后，模型的"记忆"就冻结了

2. **容易产生幻觉**
   - 当模型不知道答案时，可能会"编一个看似合理的答案"

RAG 的核心目标只有一个：

> 让大模型在回答问题前，先查资料，再基于资料生成答案

## 二、整体架构一览（先有全局）

一句话总结：

> **RAG = Embedding + Vector Database + 大模型**

系统可以分为两个阶段：

- **阶段 A：准备阶段（构建知识库）**
- **阶段 B：使用阶段（回答问题）**

## 三、阶段 A：准备阶段（把书存进"AI 图书馆"）

这一阶段通常也被称为 Indexing / Ingestion 阶段。

目标只有一个：

> 把各种文档，变成"可被语义搜索"的形式

### 1️⃣ 输入：原始文档（Documents）

常见来源包括：

- PDF / Word / Markdown
- 网页
- 图片（需先 OCR）

在真实系统中，通常会先做一步非常关键的处理：

👉 **Chunking（切块）**

将文档切成 **几百字一个的文本块**

**原因：**

- Embedding 对「小段语义」更准确
- 检索时更容易命中真正相关的内容

### 2️⃣ 转化：Embedding（文本 → 向量）

Embedding Model 的作用是：

> 把文本映射为高维语义向量

**示意：**

```
"比特币是一种去中心化的数字货币"
→ [0.021, -0.77, 0.104, ..., 0.33]
```

**重要特性：**

- 语义相似的文本 → 向量距离更近
- 不依赖关键词
- 不生成文字
- 只负责 "相似度可计算"

📌 **可以理解为：**

> Embedding Model 是"语言 → 数学空间"的翻译器

### 3️⃣ 存储：Vector Database

向量不会被单独存储，而是和原文一起保存：

```json
{
  "vector": [...],
  "text": "比特币是一种去中心化的数字货币",
  "metadata": {
    "source": "bitcoin.pdf",
    "page": 12
  }
}
```

Vector Database 的核心能力是：

> 在海量向量中，极快地找出最相似的向量

**常见 Vector DB：**

- FAISS（本地）
- Milvus
- Qdrant
- Pinecone
- Weaviate

至此，一个"AI 可搜索的知识库"就构建完成了。

## 四、阶段 B：使用阶段（AI 回答问题）

这是用户真正感知到 RAG 价值的阶段。

### 1️⃣ 提问（User Query）

例如：

> "比特币和以太坊有什么区别？"

### 2️⃣ 转换问题：Embedding Query

⚠️ **非常关键的一点：**

> 文档和问题，必须使用 **同一个 Embedding Model**

问题 → 向量 Q

这样才能保证向量空间的一致性。

### 3️⃣ 检索：Vector Search（Retrieval）

系统会在 Vector Database 中执行：

> 查找与 Q 向量最相似的 K 个文本块

**常见相似度度量方式：**

- Cosine Similarity
- Dot Product
- L2 Distance

📌 **这一步只做一件事：**

> 找资料，不写答案

### 4️⃣ 生成：大模型（Generation）

最后，把三样东西一起交给大模型（如 GPT）：

1. 用户的问题
2. 检索到的相关文档片段
3. 系统提示词（约束模型行为）

大模型的职责是：

> 在给定资料的约束下，生成最终答案

这就是 RAG 中的 Generation。

## 五、三个核心概念的精准区分

### 1️⃣ Embedding Model 是什么？

- **Embedding = 文本 → 语义向量**
- **输入：** 文本
- **输出：** 向量
- **不生成内容**
- **不理解上下文**
- **只负责"语义距离"**

### 2️⃣ Vector Database 是什么？

专为"相似度搜索"设计的数据库

**特点：**

- 不按关键词查
- 不按主键查
- 而是按"意思像不像"查

### 3️⃣ RAG 是什么？

**RAG = Retrieval + Generation**

**核心思想：**

> 不让大模型"记住一切"，
> 而是让它"学会查资料 + 用资料说人话"。

## 六、一个不会混乱的心智模型

```
文档 / PDF / 网页
        ↓
 Embedding Model
        ↓
 Vector Database
        ↑
 Embedding Model
        ↑
      问题
        ↓
   检索到的资料
        ↓
      GPT
        ↓
    最终回答
```

## 七、RAG 的价值总结

RAG 带来的好处：

✅ **知识可更新**（无需重新训练模型）

✅ **明显减少幻觉**

✅ **可结合私有数据**

✅ **成本可控、工程可落地**

## 八、结语

RAG 并不是让大模型"更聪明"，
而是让系统设计 **更理性、更工程化**。

> 模型负责表达，系统负责查证。

这也是当前 AI 应用从"Demo"走向"生产"的关键一步。
